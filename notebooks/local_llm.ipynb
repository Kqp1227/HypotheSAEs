{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1ec0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "from hypothesaes.llm_local import _get_engine\n",
    "from hypothesaes.utils import get_text_for_printing\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe90276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "os.environ['OPENAI_KEY_SAE'] = os.environ['OAI_GENERAL']\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith(\"notebooks\"):\n",
    "    prefix = \"../\"\n",
    "else:\n",
    "    prefix = \"./\"\n",
    "\n",
    "df = pd.read_json(os.path.join(prefix, \"demo-data\", \"yelp-demo-val-2K.json\"), lines=True)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['stars'].values\n",
    "\n",
    "from hypothesaes.annotate import annotate\n",
    "\n",
    "concept = 'mentions a waiter or waitress by name'\n",
    "texts_to_annotate = texts[:2000]\n",
    "tasks = [(text, concept) for text in texts_to_annotate]\n",
    "\n",
    "df_annot = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 cached items; annotating 2000 uncached items\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dd71ac47f54289ad76279aa6df0343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Annotating:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hypothesaes.annotate import annotate\n",
    "\n",
    "start = time()\n",
    "ground_truth = annotate(tasks, model='gpt-4.1', n_workers=100, max_words_per_example=256)\n",
    "\n",
    "y_gt = np.array([ground_truth[concept][text] for text in texts_to_annotate])\n",
    "df_annot['ground_truth'] = y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae7a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 cached items; annotating 2000 uncached items\n",
      "Loading Qwen/Qwen3-8B in vLLM...\n",
      "ERROR 07-20 23:44:09 [core.py:586] EngineCore failed to start.\n",
      "ERROR 07-20 23:44:09 [core.py:586] Traceback (most recent call last):\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 577, in run_engine_core\n",
      "ERROR 07-20 23:44:09 [core.py:586]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "ERROR 07-20 23:44:09 [core.py:586]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 404, in __init__\n",
      "ERROR 07-20 23:44:09 [core.py:586]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 75, in __init__\n",
      "ERROR 07-20 23:44:09 [core.py:586]     self.model_executor = executor_class(vllm_config)\n",
      "ERROR 07-20 23:44:09 [core.py:586]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/executor/executor_base.py\", line 53, in __init__\n",
      "ERROR 07-20 23:44:09 [core.py:586]     self._init_executor()\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py\", line 47, in _init_executor\n",
      "ERROR 07-20 23:44:09 [core.py:586]     self.collective_rpc(\"init_device\")\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py\", line 57, in collective_rpc\n",
      "ERROR 07-20 23:44:09 [core.py:586]     answer = run_method(self.driver_worker, method, args, kwargs)\n",
      "ERROR 07-20 23:44:09 [core.py:586]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/utils/__init__.py\", line 2736, in run_method\n",
      "ERROR 07-20 23:44:09 [core.py:586]     return func(*args, **kwargs)\n",
      "ERROR 07-20 23:44:09 [core.py:586]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/worker/worker_base.py\", line 606, in init_device\n",
      "ERROR 07-20 23:44:09 [core.py:586]     self.worker.init_device()  # type: ignore\n",
      "ERROR 07-20 23:44:09 [core.py:586]     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 07-20 23:44:09 [core.py:586]   File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py\", line 145, in init_device\n",
      "ERROR 07-20 23:44:09 [core.py:586]     raise ValueError(\n",
      "ERROR 07-20 23:44:09 [core.py:586] ValueError: Free memory on device (2.35/47.54 GiB) on startup is less than desired GPU memory utilization (0.9, 42.78 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process EngineCore_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 590, in run_engine_core\n",
      "    raise e\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 577, in run_engine_core\n",
      "    engine_core = EngineCoreProc(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 404, in __init__\n",
      "    super().__init__(vllm_config, executor_class, log_stats,\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 75, in __init__\n",
      "    self.model_executor = executor_class(vllm_config)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/executor/executor_base.py\", line 53, in __init__\n",
      "    self._init_executor()\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py\", line 47, in _init_executor\n",
      "    self.collective_rpc(\"init_device\")\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py\", line 57, in collective_rpc\n",
      "    answer = run_method(self.driver_worker, method, args, kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/utils/__init__.py\", line 2736, in run_method\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/worker/worker_base.py\", line 606, in init_device\n",
      "    self.worker.init_device()  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py\", line 145, in init_device\n",
      "    raise ValueError(\n",
      "ValueError: Free memory on device (2.35/47.54 GiB) on startup is less than desired GPU memory utilization (0.9, 42.78 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Engine core initialization failed. See root cause above. Failed core proc(s): {}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mQwen\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model \u001b[38;5;129;01mand\u001b[39;00m thinking:\n\u001b[32m     22\u001b[39m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m             results = \u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_words_per_example\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menable_thinking\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m             df_annot[model_test_name] = np.array([results[concept][text] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts_to_annotate])\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _LOCAL_ENGINES[model]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HypotheSAEs/hypothesaes/annotate.py:252\u001b[39m, in \u001b[36mannotate\u001b[39m\u001b[34m(tasks, model, cache_path, n_workers, show_progress, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m uncached_tasks:\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_local_model(model):\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         \u001b[43m_local_annotate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43muncached_tasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    261\u001b[39m         _parallel_annotate(\n\u001b[32m    262\u001b[39m             tasks=uncached_tasks,\n\u001b[32m    263\u001b[39m             model=model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    268\u001b[39m             **kwargs\n\u001b[32m    269\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:15\u001b[39m, in \u001b[36m_local_annotate\u001b[39m\u001b[34m(tasks, results, cache, model, show_progress, max_words_per_example, prompt_template, max_new_tokens, temperature, max_retries, sampling_kwargs, tokenizer_kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36mget_local_completions\u001b[39m\u001b[34m(prompts, model, max_new_tokens, temperature, show_progress, tokenizer_kwargs, sampling_kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HypotheSAEs/hypothesaes/llm_local.py:42\u001b[39m, in \u001b[36m_get_engine\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in vLLM...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m engine = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenerate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m _LOCAL_ENGINES[model] = engine\n\u001b[32m     45\u001b[39m dtype = \u001b[38;5;28mgetattr\u001b[39m(engine.llm_engine.get_model_config(), \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/entrypoints/llm.py:271\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, task, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, compilation_config, **kwargs)\u001b[39m\n\u001b[32m    241\u001b[39m engine_args = EngineArgs(\n\u001b[32m    242\u001b[39m     model=model,\n\u001b[32m    243\u001b[39m     task=task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m )\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n\u001b[32m    275\u001b[39m \u001b[38;5;28mself\u001b[39m.request_counter = Counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/engine/llm_engine.py:501\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers)\u001b[39m\n\u001b[32m    498\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMEngine \u001b[38;5;28;01mas\u001b[39;00m V1LLMEngine\n\u001b[32m    499\u001b[39m     engine_cls = V1LLMEngine\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_vllm_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:124\u001b[39m, in \u001b[36mLLMEngine.from_vllm_config\u001b[39m\u001b[34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_vllm_config\u001b[39m(\n\u001b[32m    118\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m     disable_log_stats: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    123\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLLMEngine\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m               \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m               \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m               \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m               \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m               \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVLLM_ENABLE_V1_MULTIPROCESSING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:101\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.output_processor = OutputProcessor(\u001b[38;5;28mself\u001b[39m.tokenizer,\n\u001b[32m     98\u001b[39m                                         log_stats=\u001b[38;5;28mself\u001b[39m.log_stats)\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCoreClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multiprocess_mode:\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# for v0 compatibility\u001b[39;00m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_executor = \u001b[38;5;28mself\u001b[39m.engine_core.engine_core.model_executor  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:75\u001b[39m, in \u001b[36mEngineCoreClient.make_client\u001b[39m\u001b[34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EngineCoreClient.make_async_mp_client(\n\u001b[32m     72\u001b[39m         vllm_config, executor_class, log_stats)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multiprocess_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio_mode:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyncMPClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InprocClient(vllm_config, executor_class, log_stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:503\u001b[39m, in \u001b[36mSyncMPClient.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vllm_config: VllmConfig, executor_class: \u001b[38;5;28mtype\u001b[39m[Executor],\n\u001b[32m    502\u001b[39m              log_stats: \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m     \u001b[38;5;28mself\u001b[39m.is_dp = \u001b[38;5;28mself\u001b[39m.vllm_config.parallel_config.data_parallel_size > \u001b[32m1\u001b[39m\n\u001b[32m    511\u001b[39m     \u001b[38;5;28mself\u001b[39m.outputs_queue = queue.Queue[Union[EngineCoreOutputs, \u001b[38;5;167;01mException\u001b[39;00m]]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:403\u001b[39m, in \u001b[36mMPClient.__init__\u001b[39m\u001b[34m(self, asyncio_mode, vllm_config, executor_class, log_stats, client_addresses)\u001b[39m\n\u001b[32m    399\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats_update_address = client_addresses.get(\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstats_update_address\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# Engines are managed by this client.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlaunch_core_engines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine_manager\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_manager\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/contextlib.py:144\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/utils.py:434\u001b[39m, in \u001b[36mlaunch_core_engines\u001b[39m\u001b[34m(vllm_config, executor_class, log_stats, num_api_servers)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m local_engine_manager, coordinator, addresses\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# Now wait for engines to start.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m \u001b[43mwait_for_engine_startup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhandshake_socket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengines_to_handshake\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_engine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/rmovva/anaconda3/envs/hypothesaes/lib/python3.12/site-packages/vllm/v1/engine/utils.py:484\u001b[39m, in \u001b[36mwait_for_engine_startup\u001b[39m\u001b[34m(handshake_socket, addresses, core_engines, parallel_config, cache_config, proc_manager, coord_process)\u001b[39m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coord_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m coord_process.exitcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    483\u001b[39m         finished[coord_process.name] = coord_process.exitcode\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEngine core initialization failed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mSee root cause above. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m                        \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed core proc(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinished\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# Receive HELLO and READY messages from the input socket.\u001b[39;00m\n\u001b[32m    489\u001b[39m eng_identity, ready_msg_bytes = handshake_socket.recv_multipart()\n",
      "\u001b[31mRuntimeError\u001b[39m: Engine core initialization failed. See root cause above. Failed core proc(s): {}"
     ]
    }
   ],
   "source": [
    "from hypothesaes.llm_local import _LOCAL_ENGINES\n",
    "import torch\n",
    "\n",
    "# models = ['Qwen/Qwen3-0.6B', 'Qwen/Qwen3-8B', 'google/gemma-3-4b-it']\n",
    "models = ['Qwen/Qwen3-8B']\n",
    "temperatures = [0.0, 0.5, 1.0]\n",
    "thinking_options = [True, False]\n",
    "prompt_templates = ['annotate-simple', 'annotate']\n",
    "\n",
    "for model in models:\n",
    "    for temperature in temperatures:\n",
    "        for thinking in thinking_options:\n",
    "            for prompt_template in prompt_templates:\n",
    "                model_test_name = f'{model}_temperature={temperature}_thinking={thinking}_prompt={prompt_template}'\n",
    "                if model_test_name in df_annot.columns:\n",
    "                    continue\n",
    "                \n",
    "                if thinking:\n",
    "                    max_new_tokens = 1000\n",
    "                else:\n",
    "                    max_new_tokens = 10\n",
    "                if 'Qwen' not in model and thinking:\n",
    "                    continue\n",
    "                \n",
    "                results = annotate(tasks, model=model, max_words_per_example=256, max_new_tokens=max_new_tokens, temperature=temperature, prompt_template=prompt_template,\n",
    "                                   tokenizer_kwargs={'enable_thinking': thinking})\n",
    "                df_annot[model_test_name] = np.array([results[concept][text] for text in texts_to_annotate])\n",
    "    del _LOCAL_ENGINES[model]\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00195f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison to gpt-4.1:\n",
      "==================================================\n",
      "Qwen/Qwen3-0.6B_think:\n",
      "  F1 score: 0.484\n",
      "  Pearson correlation: 0.483\n",
      "  Valid annotations: 2000/2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(\"Comparison to gpt-4.1:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for col in df_annot.columns:\n",
    "    if col == 'ground_truth':\n",
    "        continue\n",
    "    \n",
    "    y_pred = df_annot[col].values\n",
    "    y_true = df_annot['ground_truth'].values\n",
    "    \n",
    "    # Only evaluate on valid predictions (0 or 1)\n",
    "    valid_mask = np.isin(y_pred, [0, 1])\n",
    "    \n",
    "    if np.sum(valid_mask) == 0:\n",
    "        print(f\"{col}: No valid predictions\")\n",
    "        continue\n",
    "    \n",
    "    y_pred_valid = y_pred[valid_mask]\n",
    "    y_true_valid = y_true[valid_mask]\n",
    "    \n",
    "    f1 = f1_score(y_true_valid, y_pred_valid)\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  F1 score: {f1:.3f}\")\n",
    "    print(f\"  Pearson correlation: {pearsonr(y_true_valid, y_pred_valid)[0]:.3f}\")\n",
    "    print(f\"  Valid annotations: {np.sum(valid_mask)}/{len(y_pred)}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesaes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
